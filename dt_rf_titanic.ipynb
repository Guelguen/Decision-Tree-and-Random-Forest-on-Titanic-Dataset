{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from graphviz import Source\n",
    "from ipywidgets import interactive\n",
    "from IPython.display import SVG,display\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customized Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion plot_tree gefunden auf\n",
    "# https://towardsdatascience.com/interactive-visualization-of-\n",
    "# decision-trees-with-jupyter-widgets-ca15dd312084\n",
    "\n",
    "def plot_tree(crit, split, depth, min_split, min_leaf=0.2):\n",
    "    '''\n",
    "    Funktion plot_tree gefunden auf\n",
    "    https://towardsdatascience.com/interactive-visualization-of-\n",
    "    decision-trees-with-jupyter-widgets-ca15dd312084\n",
    "    \n",
    "    Teilweise verändert und an Titanic-Datensatz angepasst\n",
    "    \n",
    "    DecisionTreeClassifier wird auf Trainingsdatensatz angewandt \n",
    "    und entstandener Baum geplottet\n",
    "    '''\n",
    "    estimator = DTC(random_state = 0 \n",
    "                    , criterion = crit\n",
    "                    , splitter = split\n",
    "                    , max_depth = depth\n",
    "                    , min_samples_split=min_split\n",
    "                    , min_samples_leaf=min_leaf)\n",
    "    estimator.fit(xtrain, ytrain)\n",
    "    graph = Source(export_graphviz(estimator\n",
    "                                   , out_file=None\n",
    "                                   , feature_names = \n",
    "                                     xtrain.columns.tolist()\n",
    "                                   , filled = True))\n",
    "   \n",
    "    display(SVG(graph.pipe(format='svg')))\n",
    "    return(estimator)\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "exclude =['PassengerId','Name','Ticket','Fare','Cabin']\n",
    "def prepare_dataset(data,test_size=0.1,exclude_list=exclude):\n",
    "    '''\n",
    "    Datensatz Titanic wird zu Trainings- oder/und \n",
    "    Testsatz manipuliert.\n",
    "    \n",
    "    Dazu:\n",
    "    - Entfernen von für den decision tree überflüssige Spalten \n",
    "      für bessere Entscheidungen, frei wählbar mit exclude_list\n",
    "    - nans werden entfernt (Surrogate-Variablen werden hier \n",
    "      nicht besprochen)\n",
    "    - strings werden umgelabelt, da dieser Classifier nur mit \n",
    "      numerischen Werten umgehen kann\n",
    "    '''\n",
    "    data   = data.drop(exclude_list,axis=1)\n",
    "    data   = data.dropna()\n",
    "\n",
    "    x1,x2,y1,y2 = tts(data,data.Survived,\n",
    "                      test_size=test_size,random_state=0)\n",
    "\n",
    "    x1,x2       = x1.drop('Survived',axis=1), x2.drop('Survived',axis=1)\n",
    "    x1,x2,y1,y2 = x1.reset_index(drop=True),  x2.reset_index(drop=True),\\\n",
    "                  y1.reset_index(drop=True),  y2.reset_index(drop=True)\n",
    "    \n",
    "    # convert string to floats\n",
    "    le          = LabelEncoder()\n",
    "    for el in [x1,x2]:\n",
    "        sex     = le.fit_transform(el.Sex)\n",
    "        emb     = le.fit_transform(el.Embarked)   \n",
    "        new     = pd.DataFrame({'Sex'     : sex,\n",
    "                                'Embarked': emb}) \n",
    "        el.update(new) \n",
    "        del sex, emb, new\n",
    "    return(x1, x2, y1, y2) \n",
    "  \n",
    "#------------------------------------------------------------------------  \n",
    "    \n",
    "def create_tree_list(data,n_trees,n_subset,\n",
    "                     test_size=0.1,exclude_list=exclude):\n",
    "    '''\n",
    "    Erstellt n_trees mal Decision Trees für den Datensatz Data. \n",
    "    Die Anzahl an Subsets wird durch n_subset festgelegt. \n",
    "    In dieser Funktion werden schon Trainings- und Testsatz erstellt, \n",
    "    sodass auch die Testsatzgröße 'test_size' als relativer Anteil und \n",
    "    die zu eliminierenden Spalten in 'exclude_list' als Liste vorgegeben\n",
    "    werden müssen\n",
    "    '''\n",
    "    trees      = []\n",
    "    out_of_bag = []\n",
    "    xtrain, xtest, ytrain, ytest = prepare_dataset(data,test_size,\n",
    "                                                   exclude_list)\n",
    "    \n",
    "    names = xtrain.columns.tolist()\n",
    "    for i in range(n_trees): \n",
    "        index = random.sample(names,n_subset)\n",
    "        xboot = xtrain.sample(xtrain.shape[0], replace=True, \n",
    "                              random_state=i)[index]\n",
    "        yboot = ytrain.sample(xtrain.shape[0], replace=True, \n",
    "                              random_state=i)\n",
    "        \n",
    "        bootindices = xboot.index.values\n",
    "        out_of_bag.append([xtrain.loc[~xtrain.index.isin(bootindices)],\n",
    "                           ytrain.loc[~ytrain.index.isin(bootindices)]])\n",
    "        \n",
    "        tree  = DTC()\n",
    "        tree.fit(xboot,yboot)\n",
    "        trees.append([index,tree])\n",
    "    return(trees, xtrain, xtest, ytrain, ytest,out_of_bag)\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "def out_of_bag_error(tree_list,oob_data):\n",
    "    '''\n",
    "    Berechnet den Out-Of-Bag-Error von eingespeisten Dataframes \n",
    "    (oob_data) über eine Liste von Decision Trees (tree_list), \n",
    "    welche als Random Forest fungieren. \n",
    "    Für len(oob_data) Dataframes werden sowohl Mittelwert als auch\n",
    "    Median für den oob-Error = 1- accuracy berechnet und davon dann \n",
    "    auch nochmal jeweils Mittelwert und Median\n",
    "    '''\n",
    "    n       = len(tree_list)\n",
    "    errors  = np.zeros((n,2))\n",
    "    \n",
    "    for i in range(n):\n",
    "        x = oob_data[i][0]\n",
    "        y = oob_data[i][1]\n",
    "        \n",
    "        error = np.zeros((len(y),1))\n",
    "        \n",
    "        indices, trees = [list(el) for el in zip(*tree_list)]\n",
    "        values  = [tree.predict(x[index]) \n",
    "                   for index,tree in zip(indices,trees)]    \n",
    "        summe   = np.array((sum(values)/100)).reshape(len(y),1)\n",
    "        \n",
    "        error[y == 0] = summe[y == 0]\n",
    "        error[y == 1] = 1 - summe[y == 1]\n",
    "        errors[i] = np.array((np.mean(error),np.median(error)))\n",
    "    return(np.mean(errors[:,0]),np.median(errors[:,0]),\n",
    "           np.mean(errors[:,1]),np.median(errors[:,1]))\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "def predict_samples(data,n_trees=100,n_subset=4,\n",
    "                   test_size=0.1,exclude_list=exclude):\n",
    "    '''\n",
    "    Diese Funktion sagt als RandomForest-Algorithmus die Werte \n",
    "    0 (tot), 1 (überlebt), -1 (50/50,also keine Entscheidung) voraus. \n",
    "    Input ist der Originaldatensatz und die Variablen wie in obiger \n",
    "    Funktion beschrieben. Der Output sind \n",
    "    die Vorhersagen(Series),\n",
    "    ytest(Series), also die echten Werte,\n",
    "    die Genauigkeit acc(int) und\n",
    "    n_ties, also die Werte = -1 und damit Anzahl an Gleichständen    \n",
    "    '''\n",
    "    tree_list,xtrain, xtest, ytrain, ytest = create_tree_list(data,\n",
    "                                                             n_trees,\n",
    "                                                             n_subset,\n",
    "                                                             test_size,\n",
    "                                                             exclude_list)[:5]\n",
    "    n       = len(tree_list)\n",
    "    indices, trees = [list(el) for el in zip(*tree_list)]\n",
    "    values  = [tree.predict(xtest[index]) \n",
    "               for index,tree in zip(indices,trees)]    \n",
    "    summe   = sum(values)\n",
    "    predictions = pd.Series(0,index=np.arange(0,xtest.shape[0]))\n",
    "    predictions[summe >  n/2] =  1\n",
    "    predictions[summe == n/2] = -1\n",
    "    n_ties = np.count_nonzero(predictions == -1)\n",
    "    acc = accuracy_score(ytest,predictions)\n",
    "    return(predictions,ytest,acc,n_ties) \n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "def improve_accuracy(data,n_trees=100,n_subset_list=[2,3,4],\n",
    "                    test_size=0.1,exclude_list=exclude):\n",
    "    '''\n",
    "    Mit dieser Funktion kann der Tuning-Parameter n_subset \n",
    "    verändert werden, um eine höhere Genauigkeit zu erzielen. \n",
    "    Dazu müssen die Vorschläge für n_subset in der Liste \n",
    "    n_subset_list gespeichert werden. Empfohlen wird die Wurzel \n",
    "    aus der Anzahl an Attributen +-1 zu nehmen. Heraus kommt eine\n",
    "    Liste an Einträgen, die wie in 'predict_samples' aufgebaut sind. \n",
    "    Die Genauigkeit ist also immer der dritte Wert. \n",
    "    '''\n",
    "    return([predict_samples(data,n_trees,n_subset=el,\n",
    "                            test_size=test_size,\n",
    "                            exclude_list=exclude_list) \n",
    "           for el in n_subset_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Code wurde die Variable `random_state`$=0$ gesetzt, damit die normalerweise zufälligen Werte nicht mehr zufällig zur besseren Nachvollziehbarkeit sind.\n",
    "\n",
    "# Decision Trees\n",
    "\n",
    "In diesem Kapitel beginne ich, mich mithilfe des Titanic-Datensatzes an *Decision Trees* heranzutasten.  \n",
    "Diese gehören, wie viele andere Klassifikationsmodelle auch, zu den *supervised* lernenden Algorithmen, das heißt, er wird bereits mit den Klassen im Datensatz trainiert. Sie können sogar für Regressionen benutzt werden. Weiterhin ist dieser Classifier ein CART-(classification and regression tree) und *greedy*, also gieriger, Algorithmus. Das bedeutet, dass ein unperfekter Baum entstehen kann, was bedeutet:  \n",
    "Es gibt bessere Vorhersagen als diese.  \n",
    "Denn auch wenn Decision Trees \n",
    "* sehr einfach zu verstehen\n",
    "* intuitiv lesbar\n",
    "* skalen-, verteilungs- und ausreißerinvariant   \n",
    "\n",
    "sind, ist der einzige Punkt, der sie nicht zum ultimativen Tool macht, ihre schlechte Genauigkeit (*Hastie T., Tibshirani R., Friedman J.: 'The Elements of Statistical Learning',2009*).\n",
    "Das hat auch damit zu tun, dass sie gegenüber noisy Daten empfindlich reagieren und damit ein Overfitting zustande kommen kann.\n",
    "\n",
    "## Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train  = pd.read_csv(\"train.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun, da die Daten geladen wurden, ist es wichtig, die Spalten, die für die Entscheidungen des Decision Trees nicht nützlich sind, zu eliminieren. Dazu schauen wir uns erstmal alle Attribute an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PassengerId: Passagiernummer\n",
    "* Survived   : ob der Passagier überlebt hat (nur im Trainingsdatensatz vorhanden)\n",
    "* Pclass     : Passagierklasse 1,2,3\n",
    "* Name       : Name des Passagiers\n",
    "* Sex        : Geschlecht des Passagiers \n",
    "* Age        : Alter des Passagiers\n",
    "* SibSp      : Anzahl an Geschwistern und Ehegatten\n",
    "* Parch      : Anzahl der Elternteile und Kinder\n",
    "* Ticket     : Ticketnummer\n",
    "* Fare       : Fährkosten\n",
    "* Cabin      : Kabinennummer\n",
    "* Embarked   : Ort des Zustiegs (S,C,Q)\n",
    "\n",
    "Im nächsten Schritt übernimmt die Funktion `prepare_dataset` das Eliminieren der Spalten PassengerId, Survived, Name, Ticket, Fare und Cabin, entfernt Samples mit `nan`, bereitet den x und y Trainingsdatensatz vor und labelt Strings zu numerischen Werten um, da dieser Classifier nicht mit Strings umgehen kann. Der Testsatz wird auch entsprechend manipuliert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = prepare_dataset(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch das Entfernen der `nan`-Zeilen wurde der Trainingsssatz erheblich ausgedünnt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingssatz Originalgröße: (891, 12)   Ausgedünnt: (640, 6)   Zeilenverlust: 251\n"
     ]
    }
   ],
   "source": [
    "print('Trainingssatz Originalgröße: ' \n",
    "      + str(train.shape)\n",
    "      + '   Ausgedünnt: '\n",
    "      + str(xtrain.shape)\n",
    "      + '   Zeilenverlust: '\n",
    "      + str(train.shape[0]-xtrain.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So sieht der Trainingssatz nun aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass Sex   Age  SibSp  Parch Embarked\n",
       "0       2   0  18.0      0      2        2\n",
       "1       2   0  30.0      3      0        2\n",
       "2       3   1  42.0      0      1        2\n",
       "3       1   1  40.0      0      0        2\n",
       "4       2   1   2.0      1      1        2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Testsatz hat folgende Größe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 6)\n"
     ]
    }
   ],
   "source": [
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wollen wir den Algorithmus trainieren und anschließend einen Baum plotten.   \n",
    "Aus Platzgründen wurde hier eine Baumtiefe von $2$ gewählt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"522pt\" height=\"269pt\"\r\n",
       " viewBox=\"0.00 0.00 521.50 269.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 265)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-265 517.5,-265 517.5,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.325490\" stroke=\"black\" d=\"M306.5,-261C306.5,-261 200.5,-261 200.5,-261 194.5,-261 188.5,-255 188.5,-249 188.5,-249 188.5,-205 188.5,-205 188.5,-199 194.5,-193 200.5,-193 200.5,-193 306.5,-193 306.5,-193 312.5,-193 318.5,-199 318.5,-205 318.5,-205 318.5,-249 318.5,-249 318.5,-255 312.5,-261 306.5,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"253.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Sex &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"253.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.481</text>\r\n",
       "<text text-anchor=\"middle\" x=\"253.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 640</text>\r\n",
       "<text text-anchor=\"middle\" x=\"253.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [382, 258]</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.694118\" stroke=\"black\" d=\"M232.5,-157C232.5,-157 134.5,-157 134.5,-157 128.5,-157 122.5,-151 122.5,-145 122.5,-145 122.5,-101 122.5,-101 122.5,-95 128.5,-89 134.5,-89 134.5,-89 232.5,-89 232.5,-89 238.5,-89 244.5,-95 244.5,-101 244.5,-101 244.5,-145 244.5,-145 244.5,-151 238.5,-157 232.5,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass &lt;= 2.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.359</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 230</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [54, 176]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.773,-192.884C224.843,-184.243 218.376,-174.819 212.181,-165.793\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"214.897,-163.564 206.353,-157.299 209.125,-167.525 214.897,-163.564\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"201.78\" y=\"-178.178\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.749020\" stroke=\"black\" d=\"M372.5,-157C372.5,-157 274.5,-157 274.5,-157 268.5,-157 262.5,-151 262.5,-145 262.5,-145 262.5,-101 262.5,-101 262.5,-95 268.5,-89 274.5,-89 274.5,-89 372.5,-89 372.5,-89 378.5,-89 384.5,-95 384.5,-101 384.5,-101 384.5,-145 384.5,-145 384.5,-151 378.5,-157 372.5,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"323.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age &lt;= 3.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"323.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\r\n",
       "<text text-anchor=\"middle\" x=\"323.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 410</text>\r\n",
       "<text text-anchor=\"middle\" x=\"323.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [328, 82]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>0&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M276.227,-192.884C282.157,-184.243 288.624,-174.819 294.819,-165.793\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"297.875,-167.525 300.647,-157.299 292.103,-163.564 297.875,-167.525\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"305.22\" y=\"-178.178\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.952941\" stroke=\"black\" d=\"M101,-53C101,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,-0 12,-0 12,-0 101,-0 101,-0 107,-0 113,-6 113,-12 113,-12 113,-41 113,-41 113,-47 107,-53 101,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.083</text>\r\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 139</text>\r\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 133]</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M139.082,-88.9485C126.173,-79.3431 112.104,-68.8747 99.297,-59.345\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"101.2,-56.3984 91.088,-53.2367 97.0213,-62.0143 101.2,-56.3984\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.105882\" stroke=\"black\" d=\"M232,-53C232,-53 143,-53 143,-53 137,-53 131,-47 131,-41 131,-41 131,-12 131,-12 131,-6 137,-0 143,-0 143,-0 232,-0 232,-0 238,-0 244,-6 244,-12 244,-12 244,-41 244,-41 244,-47 238,-53 232,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.498</text>\r\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 91</text>\r\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [48, 43]</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M184.899,-88.9485C185.248,-80.7153 185.623,-71.848 185.977,-63.4814\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"189.484,-63.3758 186.411,-53.2367 182.491,-63.0797 189.484,-63.3758\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.545098\" stroke=\"black\" d=\"M361,-53C361,-53 280,-53 280,-53 274,-53 268,-47 268,-41 268,-41 268,-12 268,-12 268,-6 274,-0 280,-0 280,-0 361,-0 361,-0 367,-0 373,-6 373,-12 373,-12 373,-41 373,-41 373,-47 367,-53 361,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"320.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.43</text>\r\n",
       "<text text-anchor=\"middle\" x=\"320.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\r\n",
       "<text text-anchor=\"middle\" x=\"320.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 11]</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M322.451,-88.9485C322.189,-80.7153 321.908,-71.848 321.642,-63.4814\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"325.133,-63.1206 321.317,-53.2367 318.136,-63.3428 325.133,-63.1206\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.780392\" stroke=\"black\" d=\"M501.5,-53C501.5,-53 403.5,-53 403.5,-53 397.5,-53 391.5,-47 391.5,-41 391.5,-41 391.5,-12 391.5,-12 391.5,-6 397.5,-0 403.5,-0 403.5,-0 501.5,-0 501.5,-0 507.5,-0 513.5,-6 513.5,-12 513.5,-12 513.5,-41 513.5,-41 513.5,-47 507.5,-53 501.5,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"452.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.295</text>\r\n",
       "<text text-anchor=\"middle\" x=\"452.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 394</text>\r\n",
       "<text text-anchor=\"middle\" x=\"452.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [323, 71]</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>4&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M368.618,-88.9485C381.73,-79.3431 396.02,-68.8747 409.029,-59.345\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"411.369,-61.9698 417.367,-53.2367 407.232,-56.3228 411.369,-61.9698\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1074430da0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc = DTC(max_depth=2,random_state=0)\n",
    "dc.fit(xtrain,ytrain)\n",
    "\n",
    "names = xtrain.columns.tolist()\n",
    "\n",
    "dot_data = export_graphviz(dc,\n",
    "                           feature_names = names,\n",
    "                           out_file = None,\n",
    "                           filled   = True,\n",
    "                           rounded  = True)\n",
    "graph = Source(dot_data,filename='tree.png',format='png')\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie ist dieser Baum zu interpretieren?  \n",
    "Für diesen Algorithmus ist es umso einfacher, wenn auf einer Seite mehr Personen sind als auf der anderen. Annähernd gleiche Verteilungen sind für ihn schwierig. Genau das drückt der Gini-Index aus. Je höher er liegt, desto unreiner ist der Knoten. Durch ihn wird auch entschieden, welches Attribut nach oben kommt. Oben in der Wurzel werden die $640$ Passagiere nach den Geschlechtern getrennt, $<= 0.5$ heißt $=0$ und nach unserem Label weiblich. Ist das also wahr, gehen wir nach links, ist die Person männlich, gehen wir nach rechts. In der Wurzel wird auch bereits angegeben, dass es $382$ Frauen und $258$ Männer gibt. Gehen wir nun nach links, ist die nächste Abfrage die der Passagierklasse. Gehört die Frau zur ersten oder zweiten Klasse, gehen wir nach links, für die dritte nach rechts. Nun ist es hier so, dass von $139$ Frauen aus der ersten und zweiten Klasse $6$ überleben und $133$ umkommen. Man beachte, dass der Gini-Index hier fast rein ist, da die Anteile auch extrem verteilt sind. In der dritten Klasse ist er wiederum sehr hoch, da die Passagierzahl recht gleichmäßig aufgeteilt ist. \n",
    "\n",
    "Im Testsatz dürfen auch  `nan` vorkommen, denn Decision Trees kommen nach dem Lernen auch mit fehlenden Informationen aus. Jede Lücke kann durch sogenannte Surrogate-Variablen aufgefangen werden. Dies wird hier jedoch erstmal nicht behandelt.  \n",
    "\n",
    "Die Besonderheit im folgenden Code ist, dass durch das Package `ìpywidgets` der Decision Tree interaktiv verändert werden kann:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87ac380910b47c6b8ef2e470d3d43cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='crit', options=('gini', 'entropy'), value='gini'), Dropdown(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inter=interactive(plot_tree, \n",
    "                  crit = [\"gini\", \"entropy\"],\n",
    "                  split = [\"best\", \"random\"],\n",
    "                  depth=[1,2,3,4,5,6,7],\n",
    "                  min_split=(0.1,1),\n",
    "                  min_leaf=(0.1,0.5))\n",
    "\n",
    "display(inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schauen wir uns nun die Vorhersagen und deren Genauigkeit an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit: 77.8 %\n",
      "Das heißt: 16 von 72 Samples wurden falsch klassifiziert\n"
     ]
    }
   ],
   "source": [
    "labels = dc.predict(xtest)\n",
    "acc    = accuracy_score(ytest,labels)\n",
    "print('Genauigkeit: ' \n",
    "      + str('{:3.1f}'.format(acc*100))\n",
    "      + ' %\\nDas heißt: '\n",
    "      + str(int(len(labels)-acc*len(labels)))\n",
    "      + ' von '\n",
    "      + str(len(labels))\n",
    "      + ' Samples wurden falsch klassifiziert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das halte ich für eine zu niedrige Genauigkeit. Auch ist die Varianz, also die Instabilität beim Repitieren der Genauigkeit, sehr hoch. Ein möglicher Grund kann der recht überschaubare Datensatz oder das falsche *Pruning*, also Schneiden des Baumes, sein. Natürlich kann man das Kriterium noch ändern und statt des Gini-Indizes die Entropie, das Chi-Quadrat oder die Varianz-Reduktion wählen, wobei für diesen Classifier die letzten beiden nicht explizit verfügbar sind. Vielleicht kam hier auch ein Overfitting zustande. Dies kann durch sogenannte *Random Forests* eliminiert werden.\n",
    "\n",
    "# Random Forests\n",
    "\n",
    "Ein *Random Forest* besteht nicht aus einem einzigen Decision Tree, sondern, wie der Name sagt, aus einem ganzen Wald zufällig gewählter, nicht-beschnittener Bäume. Bei der Klassifikationsmethode wird dann durch Mehrheitsbeschluss ein endgültiges Ergebnis ermittelt. So kann ein Overfitting vermieden und die Gefahr durch ausreißende Bäume bzw. Fehlentscheidungen minimiert werden. Durch dieses Vorgehen ist die Vorhersage-Genauigkeit wesentlich höher als durch einen einzigen Decision Tree.  \n",
    "\n",
    "In diesem Kapitel werde ich wie folgt vorgehen:\n",
    "Ich werde den RandomForest-Algorithmus stückweise aufbauen, bis der DecisionTreeClassifier angewandt werden kann. Natürlich gibt es bereits den RandomForestClassifier in Python. Diesen werde ich nochmal zum Vergleich der Genauigkeit mit dem manuellen Algorithmus und dem Decision Tree aus dem vorherigen Kapitel am Ende anwenden.  \n",
    "\n",
    "## manueller Algorithmus\n",
    "In folgendem Bild sehen wir eine endliche, vom Benutzer festgelegte Anzahl $n$ an Bäumen. Diese können einen unterschiedlichen Aufbau, eine andere Wurzel oder unterschiedliche Baumtiefen haben. Wie kommt dies zustande?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Aufbau eines Random Forests](randomforesttrees.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap\n",
    "Der Originaldatensatz, in diesem Fall der Trainingssatz, mit (Zeilen-)Länge $l$ wird dem Bootstrap-Verfahren unterzogen. Dazu werden $n$ Datensätze wie folgt konstruiert:  \n",
    "Es wird $l$ mal zufällig ein Sample aus dem Trainingssatz gezogen, sodass Original und gebootstraptes Set dieselbe Größe haben. Dabei wird dieses Sample sozusagen wieder zurückgelegt, sodass Wiederholungen innerhalb jedes Satzes erlaubt und sogar erwünscht sind.  \n",
    "In diesem Beispiel gilt bzw. wurde festgelegt:  \n",
    "* Anzahl der Bäume:$n =100$\n",
    "* Länge jedes Datensatzes: $l=640$  \n",
    "\n",
    "Folgender Code stammt aus obiger Funktion `create_tree_list` und wird zum Nachvollziehen nochmal stückweise angewendet. Zunächst wird eine leere Liste für die $100$ Bäume erstellt. In `names` speichern wir alle möglichen Spaltennamen des Trainingsdatensatzes: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "trees = []\n",
    "names = xtrain.columns.tolist()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Unterschied zwischen RandomForest- und DecisionTree-Algorithmus ist, dass beim RandomForest nicht alle Attribute betrachtet werden, sondern nur ein sogenanntes *subset*. Hier werden nun statt allen, also $6$, nur $4$ Attribute in den Algorithmus eingespeist. Um die optimale Wahl dieses Tuning-Parameteres kümmern wir uns später. Die Attribut-Auswahl geschieht zufällig und wird der Variable `index` zugeschrieben. In `xboot` wird der Bootstrap-Datensatz gespeichert und seine Labels in `yboot`. Anschließend werden diese in den DecisonTreeClassifier eingespeist und die Attribut-Labels und die Bäume in der Liste `trees` gespeichert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Parch', 'Sex', 'Embarked']\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "for i in range(100): \n",
    "    index = random.sample(names,3)\n",
    "    xboot = xtrain.sample(xtrain.shape[0], replace=True, \n",
    "                          random_state=i)[index]\n",
    "    yboot = ytrain.sample(xtrain.shape[0], replace=True, \n",
    "                          random_state=i)\n",
    "    tree  = DTC()\n",
    "    tree.fit(xboot,yboot)\n",
    "    trees.append([index,tree])\n",
    "print(trees[0][0])\n",
    "print(trees[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-Of-Bag-Error\n",
    "Bereits hier kann der *Out-Of-Bag-Error* festgestellt werden. Zunächst werden aus den Bootstrap-Sets alle Beobachtungen, die nicht in die Decision Trees eingeflossen sind, gesammelt. Das ist der sogenannte Out-Of-Bag-Datensatz. Dieser wird dann auf die bereits erstellten Bäume angewendet und vorhergesagt. Da aber die Labels für diese Beobachtungen bereits feststehen, kann durch diesen Vorgang überprüft werden, wie gut sich die Bäume verhalten.  \n",
    "Die Formel für diesen Fehler lautet: $\\delta=1-acc$.  \n",
    "Man berechnet für jedes Sample in jedem der $100$ Datensätze diesen Fehler und nimmt gängigerweise dann den Mittelwert. Ich habe noch den Median dazugenommen. So kommen dann $100$ Mittelwerte und $100$ Mediane zustande. Am Ende werden nochmal daraus Mittelwerte und Mediane berechnet, sodass wir $4$ Werte haben.  \n",
    "Anzumerken ist hier noch, dass die Funktion `out_of_bag_error` mit rund $42$ s sehr langsam ist. Das liegt auch daran, dass der Algorithmus mindestens $n\\_trees * length(each\\_dataset)$ Operationen ausführen muss. In diesem Fall $100*240$, also ~$24.000$ mal.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "created  = create_tree_list(train,100,4)\n",
    "treelist = created[0]\n",
    "oobdata  = created[-1]\n",
    "mean_med = out_of_bag_error(treelist,oobdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mittelwert des Mittelwerts: 0.1840\t\tMittelwert des Medians: 0.1118\n",
      "Median des Mittelwerts:     0.1841\t\tMedian des Median: \t0.1100\n"
     ]
    }
   ],
   "source": [
    "print('Mittelwert des Mittelwerts: ' \n",
    "      + str('{:6.4f}'.format(mean_med[0]))\n",
    "      + '\\t\\tMittelwert des Medians: ' \n",
    "      + str('{:6.4f}'.format(mean_med[2]))\n",
    "      + '\\nMedian des Mittelwerts:     ' \n",
    "      + str('{:6.4f}'.format(mean_med[1]))\n",
    "      + '\\t\\tMedian des Median: ' \n",
    "      + '\\t' + str('{:6.4f}'.format(mean_med[3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allgemein liegt der Median immer etwas unter dem Mittelwert, was bedeutet, dass Ausreißer den Mittelwert nach oben ziehen. Nochmals den Mittelwert und Median des Mittelwerts und Medians zu berechnen, war in diesem Fall nicht nötig, da sie sich kaum voneinander unterscheiden. Prinzipiell sollten wir uns vor Augen führen, dass die Decision Trees, welche den Random Forest bilden, mindestens eine Fehlerrate von $10 \\%$ haben, das bedeutet, hier treffen von $100$ Bäumen mindestens $10$ die falsche Entscheidung.\n",
    "\n",
    "### Vorhersage und Klassifikation\n",
    "Im nächsten Schritt werden die Labels und Bäume separiert. Dann wird der Testsatz `xtest` durch jeden Baum vorhergesagt, sodass $100$ Listen mit jeweils $72$ Einträgen herauskommen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge der Liste 'Values': 100\n",
      "Länge eines Eintrags:     72\n"
     ]
    }
   ],
   "source": [
    "indices, trees1 = [list(el) for el in zip(*trees)]\n",
    "values  = [tree.predict(xtest[index]) \n",
    "           for index,tree in zip(indices,trees1)]\n",
    "print(\"Länge der Liste 'Values': \" \n",
    "      + str(len(values))\n",
    "      + '\\nLänge eines Eintrags:     '\n",
    "      + str(len(values[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun werden alle Listen elementweise addiert, sodass sich ein Bereich von $0 \\leq x \\leq 100$ für die $72$ Werte ergibt. Ist ein Wert nun $>50$, wird die Variable `predictions` genau an dieser Stelle $=1$ (überlebt) gesetzt. Haben wir eine Summe $=50$, also $100/2$, so setze ich ihn auf $-1$ und treffe damit also gar keine Entscheidung. Hier wäre eine andere Möglichkeit, einfach einen weiteren Baum entscheiden zu lassen, aber dann könnte ich auch einfach zufällig $0$ oder $1$ wählen. Das halte ich für keine gute Aussage. Alle Werte $\\leq 50$ sind bereits $0$ (stirbt). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "summe   = sum(values)\n",
    "\n",
    "predictions = pd.Series(0,index=np.arange(0,xtest.shape[0]))\n",
    "predictions[summe >  100/2] =  1\n",
    "predictions[summe == 100/2] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können uns nun die Genauigkeit und Anzahl an 'Non Decisions' anschauen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x wurde nicht entschieden\n",
      "Genauigkeit: 77.8 %\n"
     ]
    }
   ],
   "source": [
    "print(str(np.count_nonzero(predictions == -1))\n",
    "      + 'x wurde nicht entschieden'\n",
    "      + '\\nGenauigkeit: '\n",
    "      + str('{:3.1f}'.format(accuracy_score(ytest,predictions)*100)) \n",
    "      + ' %')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leider ist bei diesem Algorithmus die Varianz sehr hoch, d.h. bei mehrfacher Anwendung auf denselben Testsatz liegen die Genauigkeitswerte sehr weit auseinander. Nun ist hier die Genauigkeit dieselbe wie bei dem einzelnen Decision Tree und immer noch nicht zufriedenstellend. \n",
    "\n",
    "Um die Genauigkeit noch zu steigern, kann der Tuning-Parameter `n_subset` variiert werden. Mithilfe der Funktion `improve_accuracy` geht das ganz einfach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste    = [2,3,4,5,6]\n",
    "ergebnis = improve_accuracy(train,n_subset_list=liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Für m=2: 77.8 %\n",
      "Für m=3: 79.2 %\n",
      "Für m=4: 79.2 %\n",
      "Für m=5: 81.9 %\n",
      "Für m=6: 81.9 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print('Für m=' \n",
    "       + str(k) \n",
    "       + ': ' \n",
    "       + str('{:3.1f}'.format(el[2]*100)) \n",
    "       + ' %') \n",
    " for k,el in zip(liste,ergebnis)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Maximum haben wir bei $5$ oder $6$ Variablen. Damit hätten wir eine Genauigkeit von fast $82 \\%$ (was ich für einen guten Classifier für immer noch zu wenig halte). Jedoch macht es wenig Sinn, die volle Zahl an Attributen zu wählen. Die nächstgelegenere Wahl wäre also $m=4$. Somit muss der Parameter nicht mehr geändert werden. Schön zu erkennen ist hier die eben erwähnte Varianz. War der Wert zuvor $77.8 \\%$, liegt er nun bei $79.2 \\%$.\n",
    "\n",
    "## eingebetteter Algorithmus\n",
    "Zum Schluss werde ich nochmal den in Python zur Verfügung stehenden Classifier *RandomForestClassifier* mit denselben Eigenschaften und Optionen anwenden, um die Genauigkeit meines Algorithmus zu validieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit: 77.8 %\n"
     ]
    }
   ],
   "source": [
    "rc = RFC(max_features=4,random_state=0)\n",
    "rc.fit(xtrain,ytrain)\n",
    "\n",
    "ylabel = rc.predict(xtest)\n",
    "print('Genauigkeit: ' \n",
    "      + str('{:3.1f}'.format(accuracy_score(ytest,ylabel)*100)) \n",
    "      + ' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier erzielen wir wieder die gleiche Genauigkeit. Nun will ich es wissen und probiere noch andere $m$ aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit für m=2: 76.4 %\n",
      "Genauigkeit für m=3: 79.2 %\n",
      "Genauigkeit für m=4: 77.8 %\n",
      "Genauigkeit für m=5: 80.6 %\n",
      "Genauigkeit für m=6: 77.8 %\n"
     ]
    }
   ],
   "source": [
    "for i in [2,3,4,5,6]:\n",
    "    rc = RFC(max_features=i,random_state=0)\n",
    "    rc.fit(xtrain,ytrain)\n",
    "\n",
    "    ylabel = rc.predict(xtest)\n",
    "    print('Genauigkeit für m=' \n",
    "          + str(i)   \n",
    "          + ': ' \n",
    "          + str('{:3.1f}'.format(accuracy_score(ytest,ylabel)*100)) \n",
    "          + ' %') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$m=5$ scheint hier der optimale Parameter zu sein. Jedoch sehen wir beim Vergleich mit den vorherigen Werten die wiederauftretende Varianz. Deshalb ist hier jede Entscheidung mit Vorsicht zu genießen.\n",
    "\n",
    "## Fazit\n",
    "Nun habe ich einen guten Überblick über Decision Trees und Random Forests erhalten. Ein Decision Tree alleine ist nicht immer so effektiv, daher ist der RandomForest zur Klassifizierung besser geeignet.  \n",
    "Weiterhin werde ich mir für den RandomForest-Algorithmus anschauen, wie die Entscheidungswege verlaufen und Inspirationen durch andere Arbeiten einholen.\n",
    "\n",
    "Ich bedanke mich für das Interesse und Lesen dieser Arbeit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
